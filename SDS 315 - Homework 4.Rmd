---
title: "SDS 315 - Homework 4"
output: html_document
date: "2025-02-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Name: Sai Aditya Koduri
# UT EID: sk55477
# Link to GitHub: 

# Problem 1

```{r results=FALSE, echo=FALSE, warning=FALSE, message=FALSE}

simulated_flags <- rbinom(100000, 2021, 0.024)
p_value <- mean(simulated_flags >= 70)

hist(simulated_flags, breaks = 50, col = "darkolivegreen3", border = "black", main = "Distribution of Flagged Trades",
     xlab = "Number of Flagged Trades", ylab = "Frequency")
```

- The null hypothesis that we are testing is that Iron Bank's flagged rate is 2.4%, which his the baseline rate.
- The test statistic that I used to measure evidence against the null hypothesis is the p-value.
- P-Value: `r p_value`
- With the p-value being less than 0.05, the observable data about the flagged rate is highly unlikely under the null hypothesis, providing strong evidence that Iron Bank's flagged trade rate is significantly higher than the expected 2.4%.


# Problem 2

```{r results=FALSE, echo=FALSE, warning=FALSE, message=FALSE}

num_sims <- 100000
num_inspect <- 50
p_violation <- 0.03
observed_violations <- 8

simulated_violations <- rbinom(num_sims, num_inspect, p_violation)

p_value2 <- mean(simulated_violations >= observed_violations)

hist(simulated_violations, breaks = 25, col = "cornflowerblue", border = "black", main = "Distribution of Health Code Violations",
     xlab = "Number of Health Code Violations", ylab = "Frequency")
```

- The null hypothesis that we are testing is that Health Department's claim that on average the restaurants in the city are cited for the same 3% baseline rate.
- The test statistic that I used to measure evidence against the null hypothesis is the p-value.
- P-Value: `r format(p_value2, scientific = FALSE)`
- With the p-value being less than 0.05, the observable data about the health code violation rate is highly unlikely under the null hypothesis, which suggests strong statistical evidence that the Health Department's claim that on average the restaurants in the city are cited for 3% baseline rate, meaning it is probably significantly higher than the expected 3%. 


# Problem 3

```{r results=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
observed <- c(85, 56, 59, 27, 13)
expected_proportions <- c(0.30, 0.25, 0.20, 0.15, 0.10)
expected <- 240 * expected_proportions

expected

chi_test = chisq.test(observed, p = expected_proportions, rescale.p = TRUE)

chi_test
```
We first define our null hypothesis, which is that the distribution of empaneled jurors does match the expected distribution based on the county’s eligible jury pool. However, the alternate hypothesis states that the distribution of empaneled jurors is significantly different from the county’s eligible jury pool. To test this, we find the test statistic for a chi-square goodness of fit test to compare the two observed and expected distributions. We find our test statistic of X-squared = 12.426 with a degrees of freedom of 4, and a p-value of 0.01445. Since the p-value is less than 0.05, we reject the null hypothesis that the distributin of empaneled jurors does match the expected distribution based on the county's eligible jury pool currently. So we have strong statistical evidence to belive that the distribution of empaneled jurors differs significantly from expected county demographics. 

This doesn't directly suggest systematic bias, however, some issues may arise such as certain groups having lower response rates which can skew the available jury pool. We can investigate further by comparing data across groups for response rates and qualification rates.

# Problem 4

## Part A

```{r results=FALSE, echo=FALSE, warning=FALSE, message=FALSE}

brown_sentences <- readLines("brown_sentences.txt")

letter_frequency <- read.csv("letter_frequencies.csv")

letter_frequency$Probability <- letter_frequency$Probability / sum(letter_frequency$Probability)

# Function to calculate the Chi-squared statistic for a given sentence
calculateChi <- function(sentence, letterProb) {
  
  clean_sentence <- toupper(gsub("[^A-Za-z]", "", sentence))
  
  # Count occurrences of each letter in the cleaned sentence
  observed_counts <- table(factor(strsplit(clean_sentence, "")[[1]], levels = letterProb$Letter))
  
  # Calculate expected counts
  total_letters <- sum(observed_counts)
  expected_counts <- total_letters * letterProb$Probability
  
  # Compute the Chi-squared statistic
  chi_squared_stat <- sum((observed_counts - expected_counts)^2 / expected_counts, na.rm = TRUE)
  
  return(chi_squared_stat)
}

chi_squares <- sapply(brown_sentences, calculateChi, letter_frequency)

hist(chi_squares, breaks = 50, col = "coral1", border = "black", title = "Distribution of Chi-Squares")

```

## Part B

```{r results=TRUE, echo=FALSE, warning=FALSE, message=FALSE}

sentences <- c(
  "She opened the book and started to read the first chapter, eagerly anticipating what might come next.",
  "Despite the heavy rain, they decided to go for a long walk in the park, crossing the main avenue by the fountain in the center.",
  "The museum’s new exhibit features ancient artifacts from various civilizations around the world.",
  "He carefully examined the document, looking for any clues that might help solve the mystery.",
  "The students gathered in the auditorium to listen to the guest speaker’s inspiring lecture.",
  "Feeling vexed after an arduous and zany day at work, she hoped for a peaceful and quiet evening at home, cozying up after a quick dinner with some TV, or maybe a book on her upcoming visit to Auckland.",
  "The chef demonstrated how to prepare a delicious meal using only locally sourced ingredients, focusing mainly on some excellent dinner recipes from Spain.",
  "They watched the sunset from the hilltop, marveling at the beautiful array of colors in the sky.",
  "The committee reviewed the proposal and provided many points of useful feedback to improve the project’s effectiveness.",
  "Despite the challenges faced during the project, the team worked tirelessly to ensure its successful completion, resulting in a product that exceeded everyone’s expectations."
)


pValues <- c()
chiSqrVals <- c()
for (words in sentences){
  chiSqrVal <- calculateChi(words,letter_frequency)
  pValue <- sum(chi_squares >= chiSqrVal)/length(chi_squares)
  pValues <- append(pValues, pValue)
  chiSqrVals <- append(chiSqrVals, chiSqrVal)
}

pValues
chiSqrVals

```

Sentence 6 is the LLM generated sentence because we can see that it has the lowest p-value of 0.008 compared to all of the other sentences, corresponding to its chi-squared value of 96.45, meaning that this sentence deviates most from natural letter frequencies. Also, sentence 6 has the highest chi-squared value, meaning that it has the highest discrepancy between observed and expected letter distributions.